{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal(s)\n",
    "# 1. need a trainable implementation of MobileNet v1 (in PyTorch)\n",
    "# 2. Compare params with a network using normal conv\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model, disp=True):\n",
    "    \n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print('Total number of trainable parameters: {}'.format(pytorch_total_params))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(TransformerNet, self).__init__()\n",
    "        # Initial convolution layers\n",
    "        self.conv1 = ConvLayer(3, 32, kernel_size=9, stride=1)\n",
    "        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.conv2 = ConvLayer(32, 64, kernel_size=3, stride=2)\n",
    "        self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.conv3 = ConvLayer(64, 128, kernel_size=3, stride=2)\n",
    "        self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n",
    "        # Residual layers\n",
    "        self.res1 = ResidualBlock(128)\n",
    "        self.res2 = ResidualBlock(128)\n",
    "        self.res3 = ResidualBlock(128)\n",
    "        self.res4 = ResidualBlock(128)\n",
    "        self.res5 = ResidualBlock(128)\n",
    "        # Upsampling Layers\n",
    "        self.deconv1 = UpsampleConvLayer(128, 64, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.deconv2 = UpsampleConvLayer(64, 32, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.deconv3 = ConvLayer(32, 3, kernel_size=9, stride=1)\n",
    "        # Non-linearities\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "        \n",
    "        y = self.relu(self.in1(self.conv1(X)))\n",
    "        y = self.relu(self.in2(self.conv2(y)))\n",
    "        y = self.relu(self.in3(self.conv3(y)))\n",
    "        y = self.res1(y)\n",
    "        y = self.res2(y)\n",
    "        y = self.res3(y)\n",
    "        y = self.res4(y)\n",
    "        y = self.res5(y)\n",
    "        y = self.relu(self.in4(self.deconv1(y)))\n",
    "        y = self.relu(self.in5(self.deconv2(y)))\n",
    "        y = self.deconv3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class ConvLayer(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super(ConvLayer, self).__init__()\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.reflection_pad(x)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    \n",
    "    \"\"\"ResidualBlock\n",
    "    introduced in: https://arxiv.org/abs/1512.03385\n",
    "    recommended architecture: http://torch.ch/blog/2016/02/04/resnets.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.in1(self.conv1(x)))\n",
    "        out = self.in2(self.conv2(out))\n",
    "        out = out + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class UpsampleConvLayer(torch.nn.Module):\n",
    "    \n",
    "    \"\"\"UpsampleConvLayer\n",
    "    Upsamples the input and then does a convolution. This method gives better results\n",
    "    compared to ConvTranspose2d.\n",
    "    ref: http://distill.pub/2016/deconv-checkerboard/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "        super(UpsampleConvLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = torch.nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv2d(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 1679235\n"
     ]
    }
   ],
   "source": [
    "net = TransformerNet()\n",
    "print_model_size(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same transform net, but implemented with Depthwise Separable Convolutions\n",
    "import torch\n",
    "# this class implements the DwConv block introduced in MobileNet v1 paper\n",
    "class MobileNetConvBlock(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, pad=0):\n",
    "\n",
    "        super(MobileNetConvBlock, self).__init__()\n",
    "\n",
    "        self.depthwise = torch.nn.Conv2d(in_channels, in_channels, stride=stride, kernel_size=kernel_size, padding=pad, groups=in_channels)\n",
    "        #self.mnb_bn1 = torch.nn.BatchNorm2d(in_channels)\n",
    "        self.mnb_relu1 = torch.nn.ReLU()\n",
    "        self.pointwise = torch.nn.Conv2d(in_channels, out_channels, stride=1, kernel_size=1)\n",
    "        #self.mnb_bn2 = torch.nn.BatchNorm2d(out_channels)\n",
    "        self.mnb_relu2 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.depthwise(x)\n",
    "        #out = self.mnb_bn1(out)\n",
    "        out = self.mnb_relu1(out)\n",
    "        out = self.pointwise(out)\n",
    "        #out = self.mnb_bn2(out)\n",
    "        out = self.mnb_relu2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DSC_TransformerNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(DSC_TransformerNet, self).__init__()\n",
    "\n",
    "        # Initial convolution layers\n",
    "        self.conv1 = DSC_ConvLayer(3, 32, kernel_size=9, stride=1)\n",
    "        self.in1 = torch.nn.InstanceNorm2d(32, affine=True)\n",
    "        self.conv2 = DSC_ConvLayer(32, 64, kernel_size=3, stride=2)\n",
    "        self.in2 = torch.nn.InstanceNorm2d(64, affine=True)\n",
    "        self.conv3 = DSC_ConvLayer(64, 128, kernel_size=3, stride=2)\n",
    "        self.in3 = torch.nn.InstanceNorm2d(128, affine=True)\n",
    "\n",
    "        # Residual layers\n",
    "        self.res1 = DSC_ResidualBlock(128)\n",
    "        self.res2 = DSC_ResidualBlock(128)\n",
    "        self.res3 = DSC_ResidualBlock(128)\n",
    "        self.res4 = DSC_ResidualBlock(128)\n",
    "        self.res5 = DSC_ResidualBlock(128)\n",
    "\n",
    "        # Upsampling Layers\n",
    "        self.deconv1 = DSC_UpsampleConvLayer(128, 64, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in4 = torch.nn.InstanceNorm2d(64, affine=True)\n",
    "\n",
    "        self.deconv2 = DSC_UpsampleConvLayer(64, 32, kernel_size=3, stride=1, upsample=2)\n",
    "        self.in5 = torch.nn.InstanceNorm2d(32, affine=True)\n",
    "\n",
    "        self.deconv3 = DSC_ConvLayer(32, 3, kernel_size=9, stride=1)\n",
    "        # Non-linearities\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, X):\n",
    "\n",
    "        y = self.relu(self.in1(self.conv1(X)))\n",
    "        y = self.relu(self.in2(self.conv2(y)))\n",
    "        y = self.relu(self.in3(self.conv3(y)))\n",
    "        y = self.res1(y)\n",
    "        y = self.res2(y)\n",
    "        y = self.res3(y)\n",
    "        y = self.res4(y)\n",
    "        y = self.res5(y)\n",
    "        y = self.relu(self.in4(self.deconv1(y)))\n",
    "        y = self.relu(self.in5(self.deconv2(y)))\n",
    "        y = self.deconv3(y)\n",
    "        return y\n",
    "\n",
    "\n",
    "class DSC_ConvLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "\n",
    "        super(DSC_ConvLayer, self).__init__()\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = MobileNetConvBlock(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.reflection_pad(x)\n",
    "        out = self.conv2d(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DSC_ResidualBlock(torch.nn.Module):\n",
    "\n",
    "    \"\"\"ResidualBlock\n",
    "    introduced in: https://arxiv.org/abs/1512.03385\n",
    "    recommended architecture: http://torch.ch/blog/2016/02/04/resnets.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, channels):\n",
    "\n",
    "        super(DSC_ResidualBlock, self).__init__()\n",
    "        self.conv1 = DSC_ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in1 = torch.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.conv2 = DSC_ConvLayer(channels, channels, kernel_size=3, stride=1)\n",
    "        self.in2 = torch.nn.InstanceNorm2d(channels, affine=True)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.in1(self.conv1(x)))\n",
    "        out = self.in2(self.conv2(out))\n",
    "        out = out + residual\n",
    "        return out\n",
    "\n",
    "\n",
    "class DSC_UpsampleConvLayer(torch.nn.Module):\n",
    "\n",
    "    \"\"\"UpsampleConvLayer\n",
    "    Upsamples the input and then does a convolution. This method gives better results\n",
    "    compared to ConvTranspose2d.\n",
    "    ref: http://distill.pub/2016/deconv-checkerboard/\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, upsample=None):\n",
    "\n",
    "        super(DSC_UpsampleConvLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        reflection_padding = kernel_size // 2\n",
    "        self.reflection_pad = torch.nn.ReflectionPad2d(reflection_padding)\n",
    "        self.conv2d = MobileNetConvBlock(in_channels, out_channels, kernel_size, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x_in = x\n",
    "        if self.upsample:\n",
    "            x_in = torch.nn.functional.interpolate(x_in, mode='nearest', scale_factor=self.upsample)\n",
    "        out = self.reflection_pad(x_in)\n",
    "        out = self.conv2d(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 207865\n"
     ]
    }
   ],
   "source": [
    "dscnet = DSC_TransformerNet()\n",
    "print_model_size(dscnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = [i + 2*p - k]/s + 1\n",
    "# P = (F - 1)/2 when S=1\n",
    "\n",
    "class MobileNetDepthWiseConv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, n_in, n_out, stride=1):\n",
    "        \n",
    "        super(MobileNetDepthWiseConv, self).__init__()\n",
    "        \n",
    "        self.depthwise = torch.nn.Conv2d(n_in, n_in, stride=stride, kernel_size=3, padding=1, groups=n_in)\n",
    "        self.mnb_bn1 = torch.nn.BatchNorm2d(n_in)\n",
    "        self.mnb_relu1 = torch.nn.ReLU()\n",
    "        \n",
    "        self.pointwise = torch.nn.Conv2d(n_in, n_out, stride=1, kernel_size=1)\n",
    "        self.mnb_bn2 = torch.nn.BatchNorm2d(n_out)\n",
    "        self.mnb_relu2 = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.depthwise(x)\n",
    "        out = self.mnb_bn1(out)\n",
    "        out = self.mnb_relu1(out)\n",
    "        \n",
    "        out = self.pointwise(out)\n",
    "        out = self.mnb_bn2(out)\n",
    "        out = self.mnb_relu2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MobileNetv1(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(MobileNetv1, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, stride=2, kernel_size=3)\n",
    "        self.bn1   = torch.nn.BatchNorm2d(32)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        \n",
    "        self.mn1   = MobileNetDepthWiseConv(n_in=32, n_out=64, stride=1)\n",
    "        self.mn3   = MobileNetDepthWiseConv(n_in=64, n_out=128, stride=2)\n",
    "        self.mn4   = MobileNetDepthWiseConv(n_in=128, n_out=128, stride=1)\n",
    "        \n",
    "        self.mn5   = MobileNetDepthWiseConv(n_in=128, n_out=256, stride=2)\n",
    "        self.mn6   = MobileNetDepthWiseConv(n_in=256, n_out=256, stride=1)\n",
    "        \n",
    "        self.mnX   = MobileNetDepthWiseConv(n_in=256, n_out=512, stride=2)\n",
    "        \n",
    "        self.mn7   = MobileNetDepthWiseConv(n_in=512, n_out=512, stride=1)\n",
    "        self.mn8   = MobileNetDepthWiseConv(n_in=512, n_out=512, stride=1)\n",
    "        self.mn9   = MobileNetDepthWiseConv(n_in=512, n_out=512, stride=1)\n",
    "        self.mn10   = MobileNetDepthWiseConv(n_in=512, n_out=512, stride=1)\n",
    "        self.mn11   = MobileNetDepthWiseConv(n_in=512, n_out=512, stride=1)\n",
    "        \n",
    "        self.mn12   = MobileNetDepthWiseConv(n_in=512, n_out=1024, stride=2)\n",
    "        self.mn13   = MobileNetDepthWiseConv(n_in=1024, n_out=1024, stride=1)\n",
    "        \n",
    "        self.avgpool1 = torch.nn.AvgPool2d(kernel_size=7, stride=1)\n",
    "        self.fc1      = torch.nn.Linear(1024, 1000)\n",
    "        self.sm       = torch.nn.Softmax(1000)\n",
    "        # softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.mn1(x)\n",
    "        x = self.mn2(x)\n",
    "        x = self.mn4(x)\n",
    "        x = self.mn5(x)\n",
    "        x = self.mn6(x)\n",
    "        x = self.mnX(x)\n",
    "        \n",
    "        x = self.mn7(x)\n",
    "        x = self.mn8(x)\n",
    "        x = self.mn9(x)\n",
    "        x = self.mn10(x)\n",
    "        x = self.mn11(x)\n",
    "        \n",
    "        x = self.mn12(x)\n",
    "        x = self.mn13(x)\n",
    "        \n",
    "        x = self.avgpool1(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sm(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 4242920\n"
     ]
    }
   ],
   "source": [
    "mobilenet = MobileNetv1()\n",
    "print_model_size(mobilenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
